{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin\n",
    "import spacy\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    with open (file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return (data)\n",
    "\n",
    "def write_data(file, data):\n",
    "    with open (file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.util import filter_spans\n",
    "nlp = spacy.blank(\"en\") \n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin() # create a DocBin object\n",
    "    for text, annot in tqdm(TRAIN_DATA): # data in previous format\n",
    "        doc = nlp.make_doc(text) # create doc object from text\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]: # add character indexes\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"strict\")\n",
    "            if span is None:\n",
    "                pass\n",
    "            else:\n",
    "                ents.append(span)\n",
    "            \n",
    "        doc.ents = filter_spans(ents) # label the text with the ents\n",
    "        db.add(doc)\n",
    "    return (db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"data/train_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open (\"data/valid_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    valid_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From json -> spacy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6188/6188 [00:07<00:00, 842.70it/s]\n",
      "100%|██████████| 1548/1548 [00:03<00:00, 474.23it/s]\n"
     ]
    }
   ],
   "source": [
    "vlsp_2018_train = create_training(train_data)\n",
    "vlsp_2018_train.to_disk(\"data/vlsp_2018_train.spacy\")\n",
    "\n",
    "vlsp_2018_valid = create_training(valid_data)\n",
    "vlsp_2018_valid.to_disk(\"data/vlsp_2018_valid.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download base_config.cfg and make configuration from https://spacy.io/usage/training, then convert to the final training format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on local machine without GPU so it takes time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created output directory: output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2021-10-29 12:40:12,799] [INFO] Set up nlp object from config\n",
      "[2021-10-29 12:40:12,810] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2021-10-29 12:40:12,818] [INFO] Created vocabulary\n",
      "[2021-10-29 12:40:12,819] [INFO] Finished initializing nlp object\n",
      "[2021-10-29 12:40:23,397] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     17.94    0.00    0.00    0.00    0.00\n",
      "  0     200        208.62   2025.39   17.82   19.14   16.67    0.18\n",
      "  0     400        105.09   1387.86   36.55   36.19   36.91    0.37\n",
      "  0     600        156.58   1385.71   47.74   48.36   47.13    0.48\n",
      "  0     800        188.91   1314.65   59.83   62.68   57.22    0.60\n",
      "  0    1000        692.95   1634.76   61.64   67.14   56.98    0.62\n",
      "  0    1200        296.48   1687.38   65.66   70.71   61.28    0.66\n",
      "  0    1400        347.68   1878.68   66.23   72.86   60.71    0.66\n",
      "  0    1600       3921.61   2350.87   68.39   66.08   70.86    0.68\n",
      "  1    1800        625.45   2201.32   70.48   72.92   68.21    0.70\n",
      "  1    2000       1705.47   2381.19   72.14   74.68   69.77    0.72\n",
      "  1    2200        812.48   2644.11   70.55   70.76   70.34    0.71\n",
      "  2    2400        841.06   2432.54   73.31   74.02   72.61    0.73\n",
      "  3    2600        978.06   2462.78   74.27   75.14   73.43    0.74\n",
      "  3    2800        878.31   1831.32   74.53   79.18   70.39    0.75\n",
      "  4    3000        965.95   1880.38   74.45   75.28   73.63    0.74\n",
      "  4    3200        939.88   1666.76   75.03   76.97   73.18    0.75\n",
      "  5    3400        955.14   1499.38   74.66   74.75   74.57    0.75\n",
      "  5    3600        909.02   1345.82   74.51   76.20   72.88    0.75\n",
      "  6    3800       1052.71   1381.18   74.35   76.58   72.24    0.74\n",
      "  6    4000       1310.12   1393.64   75.09   76.83   73.43    0.75\n",
      "  7    4200       1149.76   1183.79   74.67   78.03   71.60    0.75\n",
      "  7    4400       1212.72   1222.15   75.61   77.54   73.78    0.76\n",
      "  8    4600        911.65   1017.30   74.89   78.23   71.82    0.75\n",
      "  8    4800       1268.81   1090.69   75.34   76.89   73.85    0.75\n",
      "  9    5000       1022.12    895.04   75.70   76.22   75.19    0.76\n",
      " 10    5200       1286.79    999.92   74.60   75.70   73.53    0.75\n",
      " 10    5400       1582.40    952.46   75.05   76.21   73.92    0.75\n",
      " 11    5600       1159.35    957.29   74.55   75.14   73.97    0.75\n",
      " 11    5800       1798.27    984.21   75.62   76.77   74.49    0.76\n",
      " 12    6000       1424.38    788.42   74.70   76.52   72.96    0.75\n",
      " 12    6200       1586.17    895.34   75.66   77.09   74.27    0.76\n",
      " 13    6400       1134.95    760.61   75.61   77.12   74.15    0.76\n",
      " 13    6600       1117.63    798.47   75.96   78.12   73.92    0.76\n",
      " 14    6800       1149.11    717.77   75.77   75.57   75.98    0.76\n",
      " 14    7000        986.45    697.05   75.67   76.60   74.76    0.76\n",
      " 15    7200       1184.75    611.01   75.76   77.31   74.27    0.76\n",
      " 15    7400       1601.85    724.39   76.15   76.88   75.43    0.76\n",
      " 16    7600       1256.62    545.43   75.09   77.01   73.26    0.75\n",
      " 17    7800       1486.30    702.83   75.21   74.74   75.68    0.75\n",
      " 17    8000       1836.88    582.09   74.66   74.71   74.62    0.75\n",
      " 18    8200       1470.96    600.05   76.20   75.96   76.45    0.76\n",
      " 18    8400       1644.97    533.19   76.04   75.81   76.27    0.76\n",
      " 19    8600       1621.48    616.19   75.64   76.43   74.86    0.76\n",
      " 19    8800       1169.94    503.12   75.46   75.95   74.99    0.75\n",
      " 20    9000       1155.90    540.08   75.40   76.48   74.34    0.75\n",
      " 20    9200       1794.10    564.59   75.98   76.25   75.71    0.76\n",
      " 21    9400       1760.95    541.79   76.74   77.51   75.98    0.77\n",
      " 21    9600       1507.13    511.72   75.73   76.97   74.52    0.76\n",
      " 22    9800       1265.25    454.12   76.65   76.91   76.40    0.77\n",
      " 22   10000       3587.08    536.23   75.39   75.92   74.86    0.75\n",
      " 23   10200       1312.85    419.53   75.63   76.78   74.52    0.76\n",
      " 24   10400       1486.53    443.60   75.47   77.22   73.80    0.75\n",
      " 24   10600       1713.11    467.15   76.06   78.41   73.85    0.76\n",
      " 25   10800       2340.49    498.43   76.06   77.85   74.34    0.76\n",
      " 25   11000       1886.24    483.57   76.36   76.94   75.78    0.76\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output/model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --output ./output --paths.train data/vlsp_2018_train.spacy --paths.dev data/vlsp_2018_valid.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Việt Nam ---- LOCATION\n",
      "Campuchia ---- LOCATION\n",
      "Mỹ Đình ---- LOCATION\n",
      "Thống Nhất Thay vìsân Thống Nhất ---- LOCATION\n",
      "sân Mỹ Đình ---- LOCATION\n",
      "Việt Nam ---- LOCATION\n",
      "Campuchia ---- LOCATION\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"output/model-best\")\n",
    "\n",
    "doc = nlp(\"Trận Việt Nam - Campuchia được chuyển ra Mỹ Đình thay vì Thống Nhất \\\n",
    "Thay vìsân Thống Nhất, sân Mỹ Đình sẽ là địa điểm tổ chức trận đấu giữa đội tuyển \\\n",
    "Việt Nam và đội tuyển Campuchia vào ngày 10.10 tới đây.\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent, \"----\", ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The results are pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pierre Vũ Ngọc Nhạ ---- PERSON\n",
      "Vũ Ngọc Nhã ---- PERSON\n",
      "Hoàng Đức Nhã ---- PERSON\n",
      "Hai Long ---- LOCATION\n",
      "Vũ Ngọc Nhạ ---- PERSON\n",
      "Vũ Ngọc Nhạ ---- PERSON\n",
      "Thái Bình ---- LOCATION\n",
      "Giáo xứ Phát Diệm ---- LOCATION\n",
      "Ninh Bình ---- LOCATION\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Giống với mọi điệp viên khác ông sử dụng rất nhiều cái tên \\\n",
    "như Pierre Vũ Ngọc Nhạ, Vũ Ngọc Nhã, Hoàng Đức Nhã, Hai Long, \\\n",
    "…nhưng người ta biết tới Thiếu tướng Vũ Ngọc Nhạ nhiều nhất vẫn \\\n",
    "qua biệt danh 'Ông cố vấn'. Vũ Ngọc Nhạ sinh năm 1928 tại Thái Bình, từ nhỏ ông \\\n",
    "đã sống tại quê mẹ ở Giáo xứ Phát Diệm, Ninh Bình.\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent, \"----\", ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The custom model did well in recognizing entities, however mislabelling\n",
    "-> We can tackle this by making it **compound words** -> spacy.blank('vi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyvi\n",
    "#pip install https://gitlab.com/trungtv/vi_spacy/-/raw/master/vi_core_news_lg/dist/vi_core_news_lg-0.0.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Giống với mọi điệp_viên khác ông sử_dụng rất nhiều cái tên như Pierre_Vũ_Ngọc_Nhạ, Vũ_Ngọc_Nhã, Hoàng_Đức_Nhã, Hai Long, …nhưng người_ta biết tới Thiếu_tướng Vũ_Ngọc_Nhạ nhiều nhất vẫn qua biệt_danh 'Ông cố_vấn'.Vũ_Ngọc_Nhạsinhnăm1928tạiThái_Bình, từnhỏ ôngđãsốngtạiquêmẹở Giáo_xứ Phát_Diệm ,Ninh_Bình.\n"
     ]
    }
   ],
   "source": [
    "vietnamese = spacy.blank('vi')\n",
    "doc = vietnamese(\"Giống với mọi điệp viên khác ông sử dụng rất nhiều cái tên \\\n",
    "như Pierre Vũ Ngọc Nhạ, Vũ Ngọc Nhã, Hoàng Đức Nhã, Hai Long, \\\n",
    "…nhưng người ta biết tới Thiếu tướng Vũ Ngọc Nhạ nhiều nhất vẫn \\\n",
    "qua biệt danh 'Ông cố vấn'. Vũ Ngọc Nhạ sinh năm 1928 tại Thái Bình, từ nhỏ ông \\\n",
    "đã sống tại quê mẹ ở Giáo xứ Phát Diệm, Ninh Bình.\")\n",
    "print(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### However, vietnamese language in spacy at this time is not good enough at capturing compound words, leading to another problem to solve.\n",
    "### For the sake of simplicity, the types of entities in the dataset are easy to label as long as entities are found."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
