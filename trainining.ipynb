{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin\n",
    "import spacy\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    with open (file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return (data)\n",
    "\n",
    "def write_data(file, data):\n",
    "    with open (file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.util import filter_spans\n",
    "nlp = spacy.blank(\"en\") \n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin() # create a DocBin object\n",
    "    for text, annot in tqdm(TRAIN_DATA): # data in previous format\n",
    "        doc = nlp.make_doc(text) # create doc object from text\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]: # add character indexes\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"strict\")\n",
    "            if span is None:\n",
    "                pass\n",
    "            else:\n",
    "                ents.append(span)\n",
    "            \n",
    "        doc.ents = filter_spans(ents) # remove duplicates\n",
    "        db.add(doc)\n",
    "    return (db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"data/train_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open (\"data/valid_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    valid_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Bộ Công Thương vừa có 'động thái mạnh mẽ, đầu tiên trong các bộ'\", {'entities': [[0, 14, 'ORGANIZATION']]}]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From json -> spacy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2209/2209 [00:02<00:00, 769.44it/s] \n",
      "100%|██████████| 2209/2209 [00:01<00:00, 1379.13it/s]\n"
     ]
    }
   ],
   "source": [
    "vlsp_2018_train = create_training(train_data)\n",
    "vlsp_2018_train.to_disk(\"data/vlsp_2018_train.spacy\")\n",
    "\n",
    "vlsp_2018_valid = create_training(valid_data)\n",
    "vlsp_2018_valid.to_disk(\"data/vlsp_2018_valid.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download base_config.cfg and make configuration from https://spacy.io/usage/training, then convert to the final training format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Being trained on local machine without GPU so it takes time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2021-11-04 19:59:55,700] [INFO] Set up nlp object from config\n",
      "[2021-11-04 19:59:55,723] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2021-11-04 19:59:55,730] [INFO] Created vocabulary\n",
      "[2021-11-04 19:59:55,730] [INFO] Finished initializing nlp object\n",
      "[2021-11-04 20:00:00,042] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     47.00    0.00    0.00    0.00    0.00\n",
      "  0     200       1078.87   2622.82   39.27   50.34   32.19    0.39\n",
      "  0     400       5218.47   1767.10   57.30   60.80   54.18    0.57\n",
      "  0     600        282.87   1483.90   67.95   69.63   66.35    0.68\n",
      "  0     800       1205.89   1411.83   77.25   81.35   73.55    0.77\n",
      "  1    1000       2082.39   1389.53   84.79   86.60   83.06    0.85\n",
      "  1    1200        313.75   1317.04   86.67   87.18   86.16    0.87\n",
      "  2    1400        561.30   1469.09   91.46   92.07   90.86    0.91\n",
      "  2    1600        641.09   1322.85   92.07   92.58   91.56    0.92\n",
      "  3    1800        680.01   1364.81   95.09   95.42   94.76    0.95\n",
      "  4    2000        612.47   1226.23   95.90   96.05   95.74    0.96\n",
      "  5    2200        775.25   1196.96   97.48   97.36   97.59    0.97\n",
      "  7    2400       1521.07   1103.18   98.17   97.96   98.38    0.98\n",
      "  9    2600        858.05   1037.75   98.65   98.63   98.67    0.99\n",
      " 10    2800        758.86    831.55   98.94   98.79   99.10    0.99\n",
      " 12    3000        758.95    647.59   98.98   98.94   99.02    0.99\n",
      " 13    3200       1029.55    654.37   99.14   99.38   98.89    0.99\n",
      " 15    3400        999.09    667.86   99.07   99.05   99.09    0.99\n",
      " 16    3600       1224.95    632.05   99.41   99.52   99.30    0.99\n",
      " 18    3800       1203.28    535.58   99.26   99.31   99.20    0.99\n",
      " 20    4000        853.20    443.36   99.34   99.26   99.43    0.99\n",
      " 21    4200        931.13    422.18   99.50   99.44   99.57    1.00\n",
      " 23    4400       1231.21    424.59   99.52   99.65   99.40    1.00\n",
      " 24    4600       1982.36    359.68   99.63   99.64   99.62    1.00\n",
      " 26    4800        888.16    383.33   99.54   99.50   99.58    1.00\n",
      " 27    5000       1847.66    391.46   99.64   99.71   99.58    1.00\n",
      " 29    5200       1339.35    419.91   99.52   99.54   99.50    1.00\n",
      " 31    5400       1092.96    322.85   99.58   99.58   99.58    1.00\n",
      " 32    5600       1939.33    322.64   99.66   99.72   99.61    1.00\n",
      " 34    5800        839.98    269.49   99.68   99.71   99.66    1.00\n",
      " 35    6000       1042.93    243.30   99.71   99.68   99.73    1.00\n",
      " 37    6200       1329.17    318.50   99.73   99.76   99.69    1.00\n",
      " 38    6400       1018.05    269.02   99.80   99.85   99.76    1.00\n",
      " 40    6600       1630.89    270.82   99.68   99.71   99.65    1.00\n",
      " 42    6800        920.20    224.17   99.72   99.79   99.65    1.00\n",
      " 43    7000        946.52    229.96   99.77   99.79   99.75    1.00\n",
      " 45    7200       1349.15    221.44   99.84   99.83   99.85    1.00\n",
      " 46    7400       1767.98    292.65   99.78   99.78   99.78    1.00\n",
      " 48    7600       1258.83    241.36   99.65   99.71   99.59    1.00\n",
      " 49    7800       1577.26    287.02   99.70   99.75   99.65    1.00\n",
      " 51    8000       1260.30    191.98   99.75   99.79   99.72    1.00\n",
      " 53    8200       1919.30    259.91   99.69   99.65   99.72    1.00\n",
      " 54    8400        851.97    179.31   99.81   99.82   99.80    1.00\n",
      " 56    8600       2027.22    192.35   99.88   99.87   99.89    1.00\n",
      " 57    8800        762.90    119.29   99.90   99.90   99.90    1.00\n",
      " 59    9000       1689.65    204.02   99.81   99.76   99.86    1.00\n",
      " 60    9200       1223.19    165.75   99.80   99.83   99.76    1.00\n",
      " 62    9400       2085.22    230.86   99.73   99.75   99.71    1.00\n",
      " 64    9600       1599.83    190.13   99.82   99.83   99.82    1.00\n",
      " 65    9800       2801.39    192.05   99.82   99.83   99.82    1.00\n",
      " 67   10000       1458.47    165.87   99.80   99.79   99.82    1.00\n",
      " 68   10200       1957.96    216.09   99.73   99.69   99.76    1.00\n",
      " 70   10400       1463.74    188.20   99.82   99.83   99.82    1.00\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output/model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --output ./output --paths.train data/vlsp_2018_train.spacy --paths.dev data/vlsp_2018_valid.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2611/2611 [00:02<00:00, 892.34it/s] \n"
     ]
    }
   ],
   "source": [
    "with open (\"data/test_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "vlsp_2018_test = create_training(test_data)\n",
    "vlsp_2018_test.to_disk(\"data/vlsp_2018_test.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalutation time!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK     100.00\n",
      "NER P   60.06 \n",
      "NER R   53.14 \n",
      "NER F   56.39 \n",
      "SPEED   22665 \n",
      "\n",
      "\u001b[1m\n",
      "=============================== NER (per type) ===============================\u001b[0m\n",
      "\n",
      "                    P       R       F\n",
      "PERSON          67.87   57.19   62.07\n",
      "ORGANIZATION    39.67   33.68   36.43\n",
      "LOCATION        65.36   67.81   66.56\n",
      "MISCELLANEOUS   38.78   12.79   19.24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy evaluate output/model-best data/vlsp_2018_test.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Việt Nam ---- LOCATION\n",
      "Campuchia ---- LOCATION\n",
      "Mỹ Đình ---- LOCATION\n",
      "Thống Nhất ---- LOCATION\n",
      "sân Mỹ Đình ---- LOCATION\n",
      "Việt Nam ---- LOCATION\n",
      "Campuchia ---- LOCATION\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"output/model-best\")\n",
    "\n",
    "doc = nlp(\"Trận Việt Nam - Campuchia được chuyển ra Mỹ Đình thay vì Thống Nhất, \\\n",
    " sân Mỹ Đình sẽ là địa điểm tổ chức trận đấu giữa đội tuyển \\\n",
    "Việt Nam và đội tuyển Campuchia vào ngày 10.10 tới đây.\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent, \"----\", ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The results are pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pierre Vũ Ngọc Nhạ ---- PERSON\n",
      "Vũ Ngọc Nhã ---- PERSON\n",
      "Hoàng Đức Nhã ---- PERSON\n",
      "Hai Long ---- LOCATION\n",
      "Vũ Ngọc Nhạ ---- PERSON\n",
      "Vũ Ngọc Nhạ ---- PERSON\n",
      "Thái Bình ---- LOCATION\n",
      "Phát Diệm ---- LOCATION\n",
      "Ninh Bình ---- LOCATION\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Giống với mọi điệp viên khác ông sử dụng rất nhiều cái tên \\\n",
    "như Pierre Vũ Ngọc Nhạ, Vũ Ngọc Nhã, Hoàng Đức Nhã, Hai Long, \\\n",
    "…nhưng người ta biết tới Thiếu tướng Vũ Ngọc Nhạ nhiều nhất vẫn \\\n",
    "qua biệt danh 'Ông cố vấn'. Vũ Ngọc Nhạ sinh năm 1928 tại Thái Bình, từ nhỏ ông \\\n",
    "đã sống tại quê mẹ ở Giáo xứ Phát Diệm, Ninh Bình.\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent, \"----\", ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The custom model did well in recognizing entities, however sometime mislabelling\n",
    "-> We can tackle this by making it **compound words** -> spacy.blank('vi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyvi\n",
    "#!pip install https://gitlab.com/trungtv/vi_spacy/-/raw/master/vi_core_news_lg/dist/vi_core_news_lg-0.0.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Giống với mọi điệp_viên khác ông sử_dụng rất nhiều cái tên như Pierre_Vũ_Ngọc_Nhạ, Vũ_Ngọc_Nhã, Hoàng_Đức_Nhã, Hai Long, …nhưng người_ta biết tới Thiếu_tướng Vũ_Ngọc_Nhạ nhiều nhất vẫn qua biệt_danh 'Ông cố_vấn'.Vũ_Ngọc_Nhạsinhnăm1928tạiThái_Bình, từnhỏ ôngđãsốngtạiquêmẹở Giáo_xứ Phát_Diệm ,Ninh_Bình.\n"
     ]
    }
   ],
   "source": [
    "vietnamese = spacy.blank('vi')\n",
    "doc = vietnamese(\"Giống với mọi điệp viên khác ông sử dụng rất nhiều cái tên \\\n",
    "như Pierre Vũ Ngọc Nhạ, Vũ Ngọc Nhã, Hoàng Đức Nhã, Hai Long, \\\n",
    "…nhưng người ta biết tới Thiếu tướng Vũ Ngọc Nhạ nhiều nhất vẫn \\\n",
    "qua biệt danh 'Ông cố vấn'. Vũ Ngọc Nhạ sinh năm 1928 tại Thái Bình, từ nhỏ ông \\\n",
    "đã sống tại quê mẹ ở Giáo xứ Phát Diệm, Ninh Bình.\")\n",
    "print(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### However, vietnamese language in spacy at this time is not good enough at capturing compound words, leading to another problem to solve.\n",
    "### For the sake of simplicity, the types of entities in the dataset are easy to label as long as entities are found."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
